
# ğŸ¤– Local AI Chatbot

A simple, private, and fully local chatbot built using **LangChain** and **Ollama** with the **Gemma 2B** model.  
The chatbot remembers conversation history during the session and responds intelligently.

---

## ğŸ“‚ Features

- ğŸ’¬ Interactive chat through the terminal.
- ğŸ§  Conversation memory (context-aware responses).
- ğŸš€ Powered by local LLM (no internet needed after setup).
- ğŸ”’ Private and secure â€” runs 100% on your machine.

---

## ğŸ› ï¸ Technologies Used

- Python
- LangChain
- Ollama
- Gemma 2B model

---

## ğŸ“¥ Installation

1. **Clone the repository**

   ```bash
   git clone https://github.com/yourusername/your-repo-name.git
   cd your-repo-name
   ```

2. **Install Python dependencies**

   ```bash
   pip install langchain langchain_ollama
   ```

3. **Install and run Ollama**

   - Install Ollama from [https://ollama.ai](https://ollama.ai)
   - Pull the **Gemma 2B** model:

     ```bash
     ollama pull gemma:2b
     ```

4. **Run the chatbot**

   ```bash
   python chatbot.py
   ```

---

## ğŸ–¥ï¸ Usage

- After running the script, type your messages in the terminal.
- To end the conversation, simply type:

  ```bash
  exit
  ```

- The bot will remember the conversation history during the session.

---

## ğŸ§© Future Improvements

- â• Add Retrieval-Augmented Generation (RAG).
- ğŸ’¾ Add long-term memory (saving chats across sessions).
- ğŸŒ Create a simple web UI (Streamlit or Gradio).
- ğŸ“š Allow document uploads for retrieval-based conversations.

---

## ğŸ“„ License

This project is licensed under the [MIT License](LICENSE).

---

## ğŸ™Œ Acknowledgements

- [LangChain](https://www.langchain.dev/)
- [Ollama](https://ollama.ai/)
- [Meta's Gemma Model](https://ai.meta.com/blog/meta-launches-gemma-open-source-models/)

---

# ğŸš€ Happy Chatting!
```
